{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0639f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dataloader import XView3Data\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from modules.metric import score, compute_loc_performance\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2, os\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51392fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TITAN Xp\n",
      "1 TITAN X (Pascal)\n",
      "2 Quadro K420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xview3/anaconda3/envs/xview3/lib/python3.9/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU2 Quadro K420 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295e321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_DN = torch.device(\"cuda:1\")\n",
    "device_RPN = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348cacf0",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646f1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "from torchvision import io, transforms as T\n",
    "\n",
    "transform = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# img = io.read_image(\"./lion.jpg\")/255\n",
    "# img = transform(img).reshape(1,3,224,224)\n",
    "# img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8bb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.featextract import FeatureExtractor\n",
    "from modules.model import RPN, DN\n",
    "from modules.config import load_model_config\n",
    "from modules.utils import evaluate, save_fig, convert_prob_to_image, prepare_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564f42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_backbone():\n",
    "    backbone = resnet50(pretrained=True)\n",
    "    for param in backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "    backbone = backbone.eval()\n",
    "    \n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0338ca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rpn = torch.nn.Sequential(*[FeatureExtractor(load_model_config(prepare_backbone())), RPN(128)])\n",
    "rpn.load_state_dict(torch.load(\"/media/xview/xview3_challenge/xView3-Challenge/exps/ckpts/RPN_4_trained_model_3_epochs.pth\"))\n",
    "rpn.to(device_RPN)\n",
    "rpn.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff64085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dn = torch.nn.Sequential(*[FeatureExtractor(load_model_config(prepare_backbone())), DN(128, 4)])\n",
    "dn.load_state_dict(torch.load(\"/media/xview/xview3_challenge/xView3-Challenge/exps/ckpts/DN_6_trained_model_3_epochs.pth\"))\n",
    "dn.to(device_DN)\n",
    "dn.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbcc3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import xgboost as xgb\n",
    "\n",
    "# xgb_clf = xgb.XGBClassifier()\n",
    "# xgb_clf.load_model(\"xgb_model.json\")\n",
    "\n",
    "# scaler = joblib.load(\"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21796f0d",
   "metadata": {},
   "source": [
    "## Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1de1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scenes detected: 50\n",
      "\tProcessing scene: 36076e547370064ev\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 203\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 203\n",
      "\tProcessing scene: 758991708403f218v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 98\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 98\n",
      "\tProcessing scene: 7b7e837a7ac5a880v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 121\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 121\n",
      "\tProcessing scene: 3fe00bf7beab8812v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 194\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 194\n",
      "\tProcessing scene: 4a97701b4bd81bf7v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 127\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 127\n",
      "\tProcessing scene: 335f9a411884e9cbv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 112\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 112\n",
      "\tProcessing scene: 75c03770095c6d9ev\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 43\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 43\n",
      "\tProcessing scene: 5e9a2c1bcf179e9bv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 187\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 187\n",
      "\tProcessing scene: 9b89b9dcce7dc85ev\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 108\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 108\n",
      "\tProcessing scene: b1844cde847a3942v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 115\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 115\n",
      "\tProcessing scene: 9a5aa7310c195f14v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 81\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 81\n",
      "\tProcessing scene: a6073537a4ea5fb9v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 140\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 140\n",
      "\tProcessing scene: cdc04ca397865356v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 44\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 44\n",
      "\tProcessing scene: a1a21a222e244555v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 115\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 115\n",
      "\tProcessing scene: 9c418af4acd217d1v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 101\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 101\n",
      "\tProcessing scene: 487b4884f467c94av\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 0\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 0\n",
      "\tProcessing scene: 128443d1e98e2839v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 56\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 56\n",
      "\tProcessing scene: acf76647ba3f524bv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 159\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 159\n",
      "\tProcessing scene: 65d6f6baee882077v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 87\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 87\n",
      "\tProcessing scene: fc2f57371370c521v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 196\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 196\n",
      "\tProcessing scene: 0d8ed29b0760dc59v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 178\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 178\n",
      "\tProcessing scene: f9eb760aaf6e798dv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 191\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 191\n",
      "\tProcessing scene: fe6a8d80fb5ebb8ev\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 208\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 208\n",
      "\tProcessing scene: fc483682c621b54bv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 106\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 106\n",
      "\tProcessing scene: 264ed833a13b7f2av\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 86\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 86\n",
      "\tProcessing scene: f298dbd78ef977d5v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 144\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 144\n",
      "\tProcessing scene: 94dca5e4de2edcf8v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 145\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 145\n",
      "\tProcessing scene: 844545c005776fb1v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 89\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 89\n",
      "\tProcessing scene: 3ceef682fbe4930av\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 60\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 60\n",
      "\tProcessing scene: 5c3d986db930f848v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 113\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 113\n",
      "\tProcessing scene: e40c9251a4fce150v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 129\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 129\n",
      "\tProcessing scene: c5ea6da5405bfac0v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 159\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 159\n",
      "\tProcessing scene: 3808f5703f0920bfv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 91\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 91\n",
      "\tProcessing scene: 377410f6ab9824dfv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 104\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 104\n",
      "\tProcessing scene: 9ea5029406691ce4v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 0\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 0\n",
      "\tProcessing scene: 13dd786ee6c95e06v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 96\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 96\n",
      "\tProcessing scene: 590dd08f71056cacv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 124\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 124\n",
      "\tProcessing scene: 4da9db72dea50504v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 104\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 104\n",
      "\tProcessing scene: cd36e75010a021f7v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 100\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 100\n",
      "\tProcessing scene: 39268d50efe8dae9v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 112\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 112\n",
      "\tProcessing scene: a9a58462f221a9eev\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 82\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 82\n",
      "\tProcessing scene: 8204efcfe9f09f94v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 0\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 0\n",
      "\tProcessing scene: 2e80028071b89173v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 0\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 0\n",
      "\tProcessing scene: 6a2b6ddecd398c6fv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 0\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 0\n",
      "\tProcessing scene: 0157baf3866b2cf9v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 61\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 61\n",
      "\tProcessing scene: eeddcc0db3cff0d8v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 112\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 112\n",
      "\tProcessing scene: c8bbfb37522617e9v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 145\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 145\n",
      "\tProcessing scene: 0e309957cef7bdc8v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 64\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 64\n",
      "\tProcessing scene: cd4f6ff86f9f5991v\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 108\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 108\n",
      "\tProcessing scene: 204e657a411faf4dv\n",
      "\tSaving in labels.json\n",
      "\tTotal chips extracted: 96\n",
      "\t\tBackground chips: 0\n",
      "\t\tForeground chips: 96\n",
      "Total chips extracted: 5294\n"
     ]
    }
   ],
   "source": [
    "def preprocess_label(df):\n",
    "    df = df.dropna(subset=[\"is_vessel\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "val_data_path = \"/media/xview/xview3_challenge/dataset/data/validation\"\n",
    "val_label_path = \"/media/xview/xview3_challenge/dataset/labels/validation1.csv\"\n",
    "\n",
    "\n",
    "val_data = XView3Data(background_chip_ratio=0.0, obj_size=5, threshold=0.25, overwrite=True,\n",
    "                        labels_path=val_label_path, data_path=val_data_path, preprocess_label=preprocess_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03bc5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_prob(fa, sr):\n",
    "    \n",
    "    joint_prob = torch.clone(sr)\n",
    "    joint_prob[:, 0, :, :] = (1-fa).squeeze(dim=1) * sr[:, 0, :, :]\n",
    "    joint_prob[:, 1:, :, :] = fa * sr[:, 1:, :, :]\n",
    "    \n",
    "    Z = torch.sum(joint_prob, dim=1, keepdim=True)\n",
    "    \n",
    "    p_ci = joint_prob / Z\n",
    "\n",
    "    return p_ci\n",
    "\n",
    "def get_detections(joint_prob):\n",
    "\n",
    "    detections = []\n",
    "    y_arr = joint_prob.detach().cpu().numpy()\n",
    "\n",
    "    y_cls = np.argmax(y_arr, axis=0)\n",
    "    y_prob = y_arr.max(axis=0)\n",
    "    y_prob_fg = 1 - y_arr[0, :, :]\n",
    "    \n",
    "    y_bin = ((y_prob_fg >= 0.5)*(y_cls!=0)).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(y_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        ix, iy = contour[:, :, 0], contour[:, :, 1]\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] == 0 and len(contour) != 0:\n",
    "            cx = 0\n",
    "            cy = 0\n",
    "            for p in contour:\n",
    "                cx += p[0][0]\n",
    "                cy += p[0][1]\n",
    "            cx = int(cx/len(contour))\n",
    "            cy = int(cy/len(contour))\n",
    "        elif len(contour) != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        cls_arr = y_cls[iy, ix]\n",
    "        val, cnt = np.unique(cls_arr, return_counts=True)\n",
    "        cls = val[np.argmax(cnt)]\n",
    "        prob = y_prob[iy, ix][cls_arr == cls].mean()\n",
    "        \n",
    "        detections.append((cx, cy, cls, prob, len(contour)))\n",
    "        \n",
    "    return detections\n",
    "\n",
    "# def get_detections(joint_prob, num_classes = 3):\n",
    "\n",
    "#     detections = []\n",
    "#     y_arr = joint_prob.detach().cpu().numpy()\n",
    "\n",
    "#     y_cls = np.argmax(y_arr, axis=0)\n",
    "#     y_prob = y_arr.max(axis=0)\n",
    "\n",
    "#     for i in range(1, num_classes+1):\n",
    "#         cls = i\n",
    "#         y_bin = ((y_cls == i)*(y_prob >= 0.9)).astype(np.uint8)\n",
    "\n",
    "#         contours, _ = cv2.findContours(y_bin, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#         for contour in contours:\n",
    "#             ix, iy = contour[:, :, 0], contour[:, :, 1]\n",
    "#             M = cv2.moments(contour)\n",
    "#             if M['m00'] == 0 and len(contour) != 0:\n",
    "#                 cx = 0\n",
    "#                 cy = 0\n",
    "#                 for p in contour:\n",
    "#                     cx += p[0][0]\n",
    "#                     cy += p[0][1]\n",
    "#                 cx = int(cx/len(contour))\n",
    "#                 cy = int(cy/len(contour))\n",
    "#             elif len(contour) != 0:\n",
    "#                 cx = int(M['m10']/M['m00'])\n",
    "#                 cy = int(M['m01']/M['m00'])\n",
    "#             else:\n",
    "#                 continue\n",
    "#             detections.append((cx, cy, cls, y_prob[iy, ix].max(), cv2.contourArea(contour)))\n",
    "        \n",
    "#     return detections\n",
    "\n",
    "# def get_detections(proposal, class_pred, num_classes=3, threshold=0.7):\n",
    "\n",
    "#     detections = []\n",
    "\n",
    "#     proposal = proposal.detach().cpu().numpy()\n",
    "#     y_arr = class_pred.detach().cpu().numpy()\n",
    "\n",
    "#     y_cls = np.argmax(y_arr, axis=0)\n",
    "#     y_prob = y_arr.max(axis=0)\n",
    "    \n",
    "#     contours, _ = cv2.findContours((proposal.squeeze() >= threshold).astype(\"uint8\"), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "#     for contour in contours:\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         if area <= 90:\n",
    "#             continue\n",
    "#         ix, iy = contour[:, :, 0], contour[:, :, 1]\n",
    "#         M = cv2.moments(contour)\n",
    "#         if M['m00'] == 0 and len(contour) != 0:\n",
    "#             cx = 0\n",
    "#             cy = 0\n",
    "#             for p in contour:\n",
    "#                 cx += p[0][0]\n",
    "#                 cy += p[0][1]\n",
    "#             cx = int(cx/len(contour))\n",
    "#             cy = int(cy/len(contour))\n",
    "#         elif len(contour) != 0:\n",
    "#             cx = int(M['m10']/M['m00'])\n",
    "#             cy = int(M['m01']/M['m00'])\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "#         cls_arr = y_cls[iy, ix]\n",
    "#         val, cnt = np.unique(cls_arr, return_counts=True)\n",
    "#         if len(val) == 1 and val[0] == 0:\n",
    "#             continue\n",
    "            \n",
    "#         val, cnt = val[val!=0], cnt[val!=0]\n",
    "#         cls = val[np.argmax(cnt)]\n",
    "#         prob = y_prob[iy, ix][cls_arr == cls].max()    \n",
    "#         detections.append((cx, cy, cls, prob, cv2.contourArea(contour)))\n",
    "        \n",
    "#     return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2051c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_ids = list(set([uid.split(\"_\")[0] for uid in val_data.data_ixs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99372774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tiff(path, out_shape, k=(49,49)):\n",
    "    data = rasterio.open(path).read(out_shape=out_shape, resampling=Resampling.bilinear).squeeze()\n",
    "    \n",
    "    blur_data = cv2.GaussianBlur(data, k, cv2.BORDER_DEFAULT)\n",
    "    return blur_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e04d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(img):\n",
    "    return np.transpose(img.cpu().numpy(), (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66278a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 111 116m 124 125m 139 140 154m 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff987e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset = val_data\n",
    "\n",
    "\n",
    "\n",
    "# l = len(dataset.data_ixs)\n",
    "# for i, uid in enumerate([dataset.data_ixs[350]], 1):\n",
    "#     scene_id, chip_row, chip_col = uid.split(\"$\")\n",
    "#     chip_row, chip_col = int(chip_row), int(chip_col)\n",
    "    \n",
    "#     scene = dataset.scenes[scene_id]\n",
    "#     rgb_img, flag = scene[chip_row, chip_col]\n",
    "    \n",
    "#     (strt_r, strt_c), _ = scene.get_full_index(chip_row, chip_col)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         rgb_img = torch.from_numpy(np.expand_dims(rgb_img, 0))\n",
    "        \n",
    "#         img = transform(rgb_img)\n",
    "#         proposal = rpn(img.to(device_RPN))\n",
    "#         class_pred = dn(img.to(device_DN))\n",
    "#         labels = scene.labels[uid]\n",
    "#         class_labels, _ = prepare_label(labels, dataset.chipsize, \n",
    "#                                             dataset.obj_size, dataset.threshold, fishing=True)\n",
    "#         class_true = torch.from_numpy(class_labels)\n",
    "        \n",
    "#         pred_im = convert_prob_to_image(class_pred[0], pred=True)\n",
    "#         true_im = convert_prob_to_image(class_true)\n",
    "        \n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(T(rgb_img[0]))\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(T(pred_im))\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(T(true_im))\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(T(proposal[0]), cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "# # plt.figure(figsize=(20,20))\n",
    "# # plt.imshow((class_labels!=0).astype(\"uint8\"), cmap=\"gray\")\n",
    "# # plt.axis(\"off\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = val_data\n",
    "# raster = \"/bathymetry.tif\"\n",
    "# predictions={\n",
    "#     \"center_x\":[],\n",
    "#     \"center_y\":[],\n",
    "#     \"scene_id\":[],\n",
    "#     \"class\":[],\n",
    "#     \"prob\":[],\n",
    "#     \"scene_h\":[],\n",
    "#     \"scene_w\":[],\n",
    "#     \"area\":[]\n",
    "# }\n",
    "\n",
    "# for scene_id in scene_ids:\n",
    "#     print(f\"\\nProcessing {scene_id}:\")\n",
    "#     uids = list(filter(lambda x: x.split(\"_\")[0]==scene_id, dataset.data_ixs))\n",
    "#     scene = dataset.scenes[scene_id]\n",
    "#     path = scene.path+raster\n",
    "#     bathymetry = load_tiff(path, out_shape=(1, scene.row, scene.col))\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     l = len(uids)\n",
    "#     for i, uid in enumerate(uids):\n",
    "#         _, chip_row, chip_col = uid.split(\"_\")\n",
    "#         chip_row, chip_col = int(chip_row), int(chip_col)\n",
    "        \n",
    "#         rgb_img, flag = scene[chip_row, chip_col]\n",
    "\n",
    "#         (strt_r, strt_c), _ = scene.get_full_index(chip_row, chip_col)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             rgb_img = torch.from_numpy(np.expand_dims(rgb_img, 0))\n",
    "\n",
    "#             img = transform(rgb_img)\n",
    "#             feat = dn[0](img.to(device_DN))\n",
    "#             feat = feat.squeeze().cpu().numpy()\n",
    "            \n",
    "#             try:\n",
    "#                 f, b = feat.reshape(-1, 800*800), bathymetry[strt_r:strt_r+dataset.chipsize, \n",
    "#                                                      strt_c:strt_c+dataset.chipsize]\n",
    "#                 h_b, w_b = b.shape\n",
    "#                 b = np.pad(b, ((0, 800-h_b), (0, 800-w_b)), constant_values=-32768)\n",
    "#                 b = b.reshape(-1)\n",
    "                \n",
    "#             except IndexError:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 x = np.hstack([f.transpose((1,0)), b.reshape(-1,1)])\n",
    "#                 scaled_x = scaler.transform(x)\n",
    "#                 pred = xgb_clf.predict_proba(scaled_x).reshape(800, 800, 4)\n",
    "                \n",
    "#                 class_pred = torch.from_numpy(np.transpose(pred, (2, 0, 1)))\n",
    "#                 detections = get_detections(class_pred)\n",
    "                \n",
    "#                 print(f\"\\r{i+1}/{l} processing... got detections: {len(detections)}  \", end=\"\")\n",
    "\n",
    "#                 for (center_x, center_y, cls, prob, area) in detections:\n",
    "#                     center_x += strt_c\n",
    "#                     center_y += strt_r\n",
    "\n",
    "#                     predictions[\"center_x\"].append(center_x)\n",
    "#                     predictions[\"center_y\"].append(center_y)\n",
    "#                     predictions[\"scene_id\"].append(scene_id)\n",
    "#                     predictions[\"class\"].append(cls)\n",
    "#                     predictions[\"prob\"].append(prob)\n",
    "#                     predictions[\"scene_h\"].append(scene.row)\n",
    "#                     predictions[\"scene_w\"].append(scene.col)\n",
    "#                     predictions[\"area\"].append(area)\n",
    "#     del bathymetry\n",
    "    \n",
    "# df = pd.DataFrame(predictions)\n",
    "# df.to_csv(\"./val_submission_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a0a7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = SummaryWriter(\"/media/xview/xview3_challenge/xView3-Challenge/exps/runs/validation_perf_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c167106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11139/11139 processing... got detections: 0   "
     ]
    }
   ],
   "source": [
    "predictions={\n",
    "    \"center_x\":[],\n",
    "    \"center_y\":[],\n",
    "    \"scene_id\":[],\n",
    "    \"class\":[],\n",
    "    \"prob\":[],\n",
    "    \"scene_h\":[],\n",
    "    \"scene_w\":[],\n",
    "    \"area\":[]\n",
    "}\n",
    "\n",
    "dataset = val_data\n",
    "\n",
    "# joblib.dump(dataset.data_ixs, \"dataset_ixs.joblib\")\n",
    "\n",
    "# pred_im = []\n",
    "# true_im = []\n",
    "\n",
    "l = len(dataset.data_ixs)\n",
    "for i, uid in enumerate(dataset.data_ixs, 1):\n",
    "    scene_id, chip_row, chip_col = uid.split(\"$\")\n",
    "    chip_row, chip_col = int(chip_row), int(chip_col)\n",
    "    \n",
    "    scene = dataset.scenes[scene_id]\n",
    "    rgb_img, flag = scene[chip_row, chip_col]\n",
    "    \n",
    "    (strt_r, strt_c), _ = scene.get_full_index(chip_row, chip_col)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rgb_img = torch.from_numpy(np.expand_dims(rgb_img, 0))\n",
    "        \n",
    "        img = transform(rgb_img)\n",
    "#         proposal = rpn(img.to(device_RPN))\n",
    "        class_pred = dn(img.to(device_DN))\n",
    "#         labels = scene.labels[uid]\n",
    "#         class_labels, _ = prepare_label(labels, dataset.chipsize, \n",
    "#                                             dataset.obj_size, dataset.threshold, fishing=True)\n",
    "#         class_true = torch.from_numpy(class_labels)\n",
    "        \n",
    "#         pred_im.append(convert_prob_to_image(class_pred[0], pred=True))\n",
    "#         true_im.append(convert_prob_to_image(class_true))\n",
    "        \n",
    "#         if i%4 == 0:\n",
    "#             writer.add_image(f'eval_class_prediction', torchvision.utils.make_grid(pred_im, nrow=2), global_step=i)\n",
    "#             writer.add_image(f'eval_class_true', torchvision.utils.make_grid(true_im, nrow=2), global_step=i)\n",
    "#             pred_im = []\n",
    "#             true_im = []\n",
    "        \n",
    "#         detections = get_detections(joint_prob(proposal, class_pred)[0])\n",
    "        detections = get_detections(class_pred[0])\n",
    "#         detections = get_detections(proposal[0], class_pred[0])\n",
    "    \n",
    "        print(f\"\\r{i}/{l} processing... got detections: {len(detections)}  \", end=\"\")\n",
    "        \n",
    "        for (center_x, center_y, cls, prob, area) in detections:\n",
    "            center_x += strt_c\n",
    "            center_y += strt_r\n",
    "            \n",
    "            predictions[\"center_x\"].append(center_x)\n",
    "            predictions[\"center_y\"].append(center_y)\n",
    "            predictions[\"scene_id\"].append(scene_id)\n",
    "            predictions[\"class\"].append(cls)\n",
    "            predictions[\"prob\"].append(prob)\n",
    "            predictions[\"scene_h\"].append(scene.row)\n",
    "            predictions[\"scene_w\"].append(scene.col)\n",
    "            predictions[\"area\"].append(area)\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "df.to_csv(\"./val_submission_9.csv\", index=False)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88e9529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(proposal.squeeze().cpu().numpy() > 0.7, cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(np.transpose(convert_prob_to_image(class_pred[0], pred=True), [2, 1, 0]))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(np.transpose(convert_prob_to_image(joint_prob(proposal, class_pred)[0], pred=True), [2, 1, 0]))\n",
    "# plt.show()\n",
    "\n",
    "# # contours, _ = cv2.findContours((proposal.squeeze().cpu().numpy() > 0.7).astype(\"uint8\"), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# # for cnt in contours:\n",
    "# #     print(cv2.contourArea(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bb0aaba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppress_land_detections(pred, owi_mask_file, k=10):\n",
    "    \n",
    "    predictions = pd.DataFrame()\n",
    "    \n",
    "    for scene_id in tqdm(np.unique(pred[\"scene_id\"])):\n",
    "        pred_scene = pred[pred[\"scene_id\"] == scene_id]\n",
    "        folder_path = os.path.join(owi_mask_file, scene_id)\n",
    "        file_path = os.path.join(folder_path, \"owiMask.tif\")\n",
    "        \n",
    "        src = rasterio.open(file_path)\n",
    "        mask = src.read(1)\n",
    "        mask = (mask == 0).astype(\"uint8\")\n",
    "        \n",
    "        h, w = pred_scene.iloc[0][\"scene_h\"], pred_scene.iloc[0][\"scene_w\"]\n",
    "        \n",
    "        mask = cv2.dilate(mask, np.ones((k, k), np.uint8))\n",
    "        mask = cv2.resize(mask, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        \n",
    "        det_r, det_c = pred_scene[\"detect_scene_row\"].values, pred_scene[\"detect_scene_column\"].values\n",
    "        \n",
    "        ix_bool = (det_r < h) & (det_c < w)\n",
    "        det_r = det_r[ix_bool]\n",
    "        det_c = det_c[ix_bool]\n",
    "        ix = np.where(mask[det_r, det_c] == 1)[0]\n",
    "        \n",
    "        predictions = pd.concat([predictions, pred_scene.iloc[ix]]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Removed {len(pred) - len(predictions)} detections from {len(pred)} detections\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "addbd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_scenes(df):\n",
    "    ids = ['2e80028071b89173v_val', '8204efcfe9f09f94v_val', '487b4884f467c94av_val', '6a2b6ddecd398c6fv_val']\n",
    "    for id in ids:\n",
    "        df.drop(index=df[df[\"scene_id\"] == id].index, inplace=True)\n",
    "    \n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12c20dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df.copy()\n",
    "# pred = pd.read_csv(\"./val_submission_5.csv\")\n",
    "gt = pd.read_csv(\"/media/xview/xview3_challenge/dataset/labels/validation1.csv\")\n",
    "gt = drop_scenes(gt)\n",
    "shore_root = \"/media/xview/xview3_challenge/dataset/Shoreline_data/validation\"\n",
    "\n",
    "\n",
    "pred[\"is_vessel\"] = ((pred[\"class\"] == 1) | (pred[\"class\"] == 2))\n",
    "\n",
    "pred[\"is_fishing\"] = pred[\"class\"] == 1\n",
    "\n",
    "pred[\"vessel_length_m\"] = 30.0\n",
    "\n",
    "pred[\"detect_scene_row\"] = pred[\"center_y\"]\n",
    "pred[\"detect_scene_column\"] = pred[\"center_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8274415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14989, 13)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "48fcc686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred[pred[\"area\"]<=150][\"area\"], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42d6fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in gt[\"scene_id\"].unique() if i not in pred[\"scene_id\"].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bae79ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 45/45 [00:01<00:00, 31.29it/s]\n",
      "100%|███████████████████████████████████████████| 45/45 [00:30<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.5547514159848961,\n",
       " 'loc_fscore_shore': 0.14326170248209227,\n",
       " 'vessel_fscore': 0.8629869462431904,\n",
       " 'fishing_fscore': 0.7699115044247788,\n",
       " 'length_acc': 0.448241235936641,\n",
       " 'aggregate': 0.35774824725990284}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred, gt, shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca90368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 60.79it/s]\n",
      "100%|███████████████████████████████████████████| 45/45 [00:20<00:00,  2.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.6433391099148262,\n",
       " 'loc_fscore_shore': 0.12276313257648644,\n",
       " 'vessel_fscore': 0.8674348593376934,\n",
       " 'fishing_fscore': 0.7743940335612182,\n",
       " 'length_acc': 0.44696784888004426,\n",
       " 'aggregate': 0.4132244142012003}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred[(pred[\"area\"] >= 25) & (pred[\"area\"] <= 150)].reset_index(drop=True), gt, shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd8e806e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 63.45it/s]\n",
      "100%|███████████████████████████████████████████| 45/45 [00:18<00:00,  2.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.6296489140136864,\n",
       " 'loc_fscore_shore': 0.17004624688722872,\n",
       " 'vessel_fscore': 0.8718294917542676,\n",
       " 'fishing_fscore': 0.7941363926067558,\n",
       " 'length_acc': 0.44351936743018705,\n",
       " 'aggregate': 0.41299068932331134}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred[(pred[\"area\"] >= 15) & (pred[\"area\"] <= 150)].reset_index(drop=True), gt, shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a69df358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 75.05it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:12<00:00,  4.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.3587805675665855,\n",
       " 'loc_fscore_shore': 0.036585365853658534,\n",
       " 'vessel_fscore': 0.8826707834812815,\n",
       " 'fishing_fscore': 0.7239819004524887,\n",
       " 'length_acc': 0.4108311553687538,\n",
       " 'aggregate': 0.21914813656271317}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred[(pred[\"area\"] >= 10) & (pred[\"area\"] <= 1000)].reset_index(drop=True), gt=gt, shore_root=shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52c32ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 61.41it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:16<00:00,  3.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.3481793447877455,\n",
       " 'loc_fscore_shore': 0.060377358490566045,\n",
       " 'vessel_fscore': 0.7938501515807711,\n",
       " 'fishing_fscore': 0.6778149386845039,\n",
       " 'length_acc': 0.48862975286846166,\n",
       " 'aggregate': 0.21034713359602128}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred=pred[(pred[\"prob\"] >= 0.5) & (pred[\"area\"] >= 110) & (pred[\"area\"] <= 750)].reset_index(drop=True), gt=gt, shore_root=shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a37d526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:05<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 402 detections from 12833 detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = suppress_land_detections(pred, \"/media/xview/xview3_challenge/dataset/data/owiMask-val\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd59b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 64.15it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:17<00:00,  2.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.6212705015855696,\n",
       " 'loc_fscore_shore': 0.10154071900220103,\n",
       " 'vessel_fscore': 0.8666797180892718,\n",
       " 'fishing_fscore': 0.7696933253156945,\n",
       " 'length_acc': 0.4447609383188643,\n",
       " 'aggregate': 0.3954603815407528}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred=predictions[predictions[\"area\"] >= 20].reset_index(drop=True), gt=gt, shore_root=shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce88042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a7b16ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 75.77it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:12<00:00,  4.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.3580808264522935,\n",
       " 'loc_fscore_shore': 0.03498047206656478,\n",
       " 'vessel_fscore': 0.8828200658531861,\n",
       " 'fishing_fscore': 0.7231467473524963,\n",
       " 'length_acc': 0.4111345282322506,\n",
       " 'aggregate': 0.21857839563594106}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred=predictions.reset_index(drop=True), gt=gt, shore_root=shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "be8eb7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 66.42it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:18<00:00,  2.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.5925297689724193,\n",
       " 'loc_fscore_shore': 0.11664538101319709,\n",
       " 'vessel_fscore': 0.791472032578752,\n",
       " 'fishing_fscore': 0.7344947735191637,\n",
       " 'length_acc': 0.4329813911724997,\n",
       " 'aggregate': 0.364476150478689}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred=predictions[(predictions[\"prob\"] >= 0.5) & (predictions[\"area\"] >= 110) & (predictions[\"area\"] <= 750)].reset_index(drop=True), gt=gt, shore_root=shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d977c91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [00:00<00:00, 64.05it/s]\n",
      "100%|███████████████████████████████████████████| 50/50 [00:18<00:00,  2.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.620715350223547,\n",
       " 'loc_fscore_shore': 0.10810027532241703,\n",
       " 'vessel_fscore': 0.866990291262136,\n",
       " 'fishing_fscore': 0.7701492537313434,\n",
       " 'length_acc': 0.4434678888939205,\n",
       " 'aggregate': 0.39585596449653915}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(pred[pred[\"area\"] >= 20].reset_index(drop=True), gt, shore_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "889fda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.metric import compute_loc_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d187fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_inds, fp_inds, fn_inds = compute_loc_performance(pred[pred[\"area\"] >=20].reset_index(drop=True), gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94fdaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = len(tp_inds)/(len(tp_inds)+len(fp_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87756314",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = len(tp_inds)/(len(tp_inds)+len(fn_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "883a8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9028155339805826, Recall: 0.4837182688306284\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f01a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0c0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "025f6d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview3",
   "language": "python",
   "name": "xview3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
